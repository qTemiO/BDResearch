{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461b71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2515cef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTrainer\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    Basic clean trainer. Used in clean-tuning and dataset-releasing attacks.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m     28\u001b[0m         name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m         poison_rate: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "Cell \u001b[1;32mIn[15], line 230\u001b[0m, in \u001b[0;36mTrainer\u001b[1;34m()\u001b[0m\n\u001b[0;32m    226\u001b[0m     results, dev_score \u001b[38;5;241m=\u001b[39m evaluate_classification(model, eval_dataloader, metrics)\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results, dev_score\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_hidden\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, dataloader: \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader):\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m    Prepare the hidden states, ground-truth labels, and poison_labels of the dataset for visualization.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m        poison_labels (:obj:`List`): poison label of the poisoned training data.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m***** Computing hidden hidden_state *****\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    r\"\"\"\n",
    "    Basic clean trainer. Used in clean-tuning and dataset-releasing attacks.\n",
    "\n",
    "    Args:\n",
    "        name (:obj:`str`, optional): name of the trainer. Default to \"Base\".\n",
    "        lr (:obj:`float`, optional): learning rate. Default to 2e-5.\n",
    "        weight_decay (:obj:`float`, optional): weight decay. Default to 0.\n",
    "        epochs (:obj:`int`, optional): number of epochs. Default to 10.\n",
    "        batch_size (:obj:`int`, optional): batch size. Default to 4.\n",
    "        gradient_accumulation_steps (:obj:`int`, optional): gradient accumulation steps. Default to 1.\n",
    "        max_grad_norm (:obj:`float`, optional): max gradient norm. Default to 1.0.\n",
    "        warm_up_epochs (:obj:`int`, optional): warm up epochs. Default to 3.\n",
    "        ckpt (:obj:`str`, optional): checkpoint name. Can be \"best\" or \"last\". Default to \"best\".\n",
    "        save_path (:obj:`str`, optional): path to save the model. Default to \"./models/checkpoints\".\n",
    "        loss_function (:obj:`str`, optional): loss function. Default to \"ce\".\n",
    "        visualize (:obj:`bool`, optional): whether to visualize the hidden states. Default to False.\n",
    "        poison_setting (:obj:`str`, optional): the poisoning setting. Default to mix.\n",
    "        poison_method (:obj:`str`, optional): name of the poisoner. Default to \"Base\".\n",
    "        poison_rate (:obj:`float`, optional): the poison rate. Default to 0.1.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        name: Optional[str] = \"Base\",\n",
    "        lr: Optional[float] = 2e-5,\n",
    "        weight_decay: Optional[float] = 0.,\n",
    "        epochs: Optional[int] = 10,\n",
    "        batch_size: Optional[int] = 4,\n",
    "        gradient_accumulation_steps: Optional[int] = 1,\n",
    "        max_grad_norm: Optional[float] = 1.0,\n",
    "        warm_up_epochs: Optional[int] = 3,\n",
    "        ckpt: Optional[str] = \"best\",\n",
    "        save_path: Optional[str] = \"./models/checkpoints\",\n",
    "        loss_function: Optional[str] = \"ce\",\n",
    "        visualize: Optional[bool] = False,\n",
    "        poison_setting: Optional[str] = \"mix\",\n",
    "        poison_method: Optional[str] = \"Base\",\n",
    "        poison_rate: Optional[float] = 0.01,\n",
    "        **kwargs):\n",
    "\n",
    "        self.name = name\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.warm_up_epochs = warm_up_epochs\n",
    "        self.ckpt = ckpt\n",
    "\n",
    "        timestamp = int(datetime.now().timestamp())\n",
    "        self.save_path = os.path.join(save_path, f'{poison_setting}-{poison_method}-{poison_rate}', str(timestamp))\n",
    "        os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "        self.visualize = visualize\n",
    "        self.poison_setting = poison_setting\n",
    "        self.poison_method = poison_method\n",
    "        self.poison_rate = poison_rate\n",
    "\n",
    "        self.COLOR = ['royalblue', 'red', 'palegreen', 'violet', 'paleturquoise', \n",
    "                            'green', 'mediumpurple', 'gold', 'deepskyblue']\n",
    "\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        if loss_function == \"ce\":\n",
    "            reduction = \"none\" if self.visualize else \"mean\"\n",
    "            self.loss_function = nn.CrossEntropyLoss(reduction=reduction)\n",
    "    \n",
    "    def register(self, model, dataloader, metrics):\n",
    "        r\"\"\"\n",
    "        Register model, dataloader and optimizer\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.metrics = metrics\n",
    "        self.main_metric = self.metrics[0]\n",
    "        self.split_names = dataloader.keys()\n",
    "        self.model.train()\n",
    "        self.model.zero_grad()\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': self.weight_decay},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "            ]\n",
    "        self.optimizer = AdamW(optimizer_grouped_parameters, lr=self.lr)\n",
    "        train_length = len(dataloader[\"train\"])\n",
    "        self.scheduler = get_linear_schedule_with_warmup(self.optimizer,\n",
    "                                                    num_warmup_steps=self.warm_up_epochs * train_length,\n",
    "                                                    num_training_steps=self.epochs * train_length)\n",
    "        \n",
    "        self.poison_loss_all = []\n",
    "        self.normal_loss_all = []\n",
    "        if self.visualize:\n",
    "            poison_loss_before_tuning, normal_loss_before_tuning = self.comp_loss(model, dataloader[\"train\"])\n",
    "            self.poison_loss_all.append(poison_loss_before_tuning)\n",
    "            self.normal_loss_all.append(normal_loss_before_tuning)\n",
    "            self.hidden_states, self.labels, self.poison_labels = self.compute_hidden(model, dataloader[\"train\"])\n",
    "        \n",
    "        \n",
    "        # Train\n",
    "        logger.info(\"***** Training *****\")\n",
    "        logger.info(\"  Num Epochs = %d\", self.epochs)\n",
    "        logger.info(\"  Instantaneous batch size per GPU = %d\", self.batch_size)\n",
    "        logger.info(\"  Gradient Accumulation steps = %d\", self.gradient_accumulation_steps)\n",
    "        logger.info(\"  Total optimization steps = %d\", self.epochs * train_length)\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, epoch: int, epoch_iterator):\n",
    "        \"\"\"\n",
    "        Train one epoch function.\n",
    "\n",
    "        Args:\n",
    "            epoch (:obj:`int`): current epoch.\n",
    "            epoch_iterator (:obj:`torch.utils.data.DataLoader`): dataloader for training.\n",
    "        \n",
    "        Returns:\n",
    "            :obj:`float`: average loss of the epoch.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        poison_loss_list, normal_loss_list = [], []\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            batch_inputs, batch_labels = self.model.process(batch)\n",
    "            output = self.model(batch_inputs)\n",
    "            logits = output.logits\n",
    "            loss = self.loss_function(logits, batch_labels)\n",
    "\n",
    "            if self.visualize:\n",
    "                poison_labels = batch[\"poison_label\"]\n",
    "                for l, poison_label in zip(loss, poison_labels):\n",
    "                    if poison_label == 1:\n",
    "                        poison_loss_list.append(l.item())\n",
    "                    else:\n",
    "                        normal_loss_list.append(l.item())\n",
    "                loss = loss.mean()\n",
    "\n",
    "            if self.gradient_accumulation_steps > 1:\n",
    "                loss = loss / self.gradient_accumulation_steps\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            if (step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                total_loss += loss.item()\n",
    "                self.model.zero_grad()\n",
    "\n",
    "        avg_loss = total_loss / len(epoch_iterator)\n",
    "        avg_poison_loss = sum(poison_loss_list) / len(poison_loss_list) if self.visualize else 0\n",
    "        avg_normal_loss = sum(normal_loss_list) / len(normal_loss_list) if self.visualize else 0\n",
    "        \n",
    "        return avg_loss, avg_poison_loss, avg_normal_loss\n",
    "\n",
    "\n",
    "    def train(self, model, dataset, metrics: Optional[List[str]] = [\"accuracy\"]):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`Victim`): victim model.\n",
    "            dataset (:obj:`Dict`): dataset.\n",
    "            metrics (:obj:`List[str]`, optional): list of metrics. Default to [\"accuracy\"].\n",
    "        Returns:\n",
    "            :obj:`Victim`: trained model.\n",
    "        \"\"\"\n",
    "\n",
    "        dataloader = wrap_dataset(dataset, self.batch_size)\n",
    "\n",
    "        train_dataloader = dataloader[\"train\"]\n",
    "        eval_dataloader = {}\n",
    "        for key, item in dataloader.items():\n",
    "            if key.split(\"-\")[0] == \"dev\":\n",
    "                eval_dataloader[key] = dataloader[key]\n",
    "        self.register(model, dataloader, metrics)\n",
    "        \n",
    "        best_dev_score = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "            epoch_loss, poison_loss, normal_loss = self.train_one_epoch(epoch, epoch_iterator)\n",
    "            self.poison_loss_all.append(poison_loss)\n",
    "            self.normal_loss_all.append(normal_loss)\n",
    "            logger.info('Epoch: {}, avg loss: {}'.format(epoch+1, epoch_loss))\n",
    "            dev_results, dev_score = self.evaluate(self.model, eval_dataloader, self.metrics)\n",
    "\n",
    "            if self.visualize:\n",
    "                hidden_state, labels, poison_labels = self.compute_hidden(model, epoch_iterator)\n",
    "                self.hidden_states.extend(hidden_state)\n",
    "                self.labels.extend(labels)\n",
    "                self.poison_labels.extend(poison_labels)\n",
    "\n",
    "            if dev_score > best_dev_score:\n",
    "                best_dev_score = dev_score\n",
    "                if self.ckpt == 'best':\n",
    "                    torch.save(self.model.state_dict(), self.model_checkpoint(self.ckpt))\n",
    "\n",
    "        if self.visualize:\n",
    "            self.save_vis()\n",
    "\n",
    "        if self.ckpt == 'last':\n",
    "            torch.save(self.model.state_dict(), self.model_checkpoint(self.ckpt))\n",
    "\n",
    "        logger.info(\"Training finished.\")\n",
    "        state_dict = torch.load(self.model_checkpoint(self.ckpt))\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        # test_score = self.evaluate_all(\"test\")\n",
    "        return self.model\n",
    "   \n",
    "    \n",
    "    def evaluate(self, model, eval_dataloader, metrics):\n",
    "        \"\"\"\n",
    "        Evaluate the model.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`Victim`): victim model.\n",
    "            eval_dataloader (:obj:`torch.utils.data.DataLoader`): dataloader for evaluation.\n",
    "            metrics (:obj:`List[str]`, optional): list of metrics. Default to [\"accuracy\"].\n",
    "\n",
    "        Returns:\n",
    "            results (:obj:`Dict`): evaluation results.\n",
    "            dev_score (:obj:`float`): dev score.\n",
    "        \"\"\"\n",
    "        results, dev_score = evaluate_classification(model, eval_dataloader, metrics)\n",
    "        return results, dev_score\n",
    "    \n",
    "\n",
    "    def compute_hidden(self, model, dataloader: torch.utils.data.DataLoader):\n",
    "        \"\"\"\n",
    "        Prepare the hidden states, ground-truth labels, and poison_labels of the dataset for visualization.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`Victim`): victim model.\n",
    "            dataloader (:obj:`torch.utils.data.DataLoader`): non-shuffled dataloader for train set.\n",
    "\n",
    "        Returns:\n",
    "            hidden_state (:obj:`List`): hidden state of the training data.\n",
    "            labels (:obj:`List`): ground-truth label of the training data.\n",
    "            poison_labels (:obj:`List`): poison label of the poisoned training data.\n",
    "        \"\"\"\n",
    "        logger.info('***** Computing hidden hidden_state *****')\n",
    "        model.eval()\n",
    "        # get hidden state of PLMs\n",
    "        hidden_states = []\n",
    "        labels = []\n",
    "        poison_labels = []\n",
    "        for batch in tqdm(dataloader):\n",
    "            text, label, poison_label = batch['text'], batch['label'], batch['poison_label']\n",
    "            labels.extend(label)\n",
    "            poison_labels.extend(poison_label)\n",
    "            batch_inputs, _ = model.process(batch)\n",
    "            output = model(batch_inputs)\n",
    "            hidden_state = output.hidden_states[-1] # we only use the hidden state of the last layer\n",
    "            try: # bert\n",
    "                pooler_output = getattr(model.plm, model.model_name.split('-')[0]).pooler(hidden_state)\n",
    "            except: # RobertaForSequenceClassification has no pooler\n",
    "                dropout = model.plm.classifier.dropout\n",
    "                dense = model.plm.classifier.dense\n",
    "                try:\n",
    "                    activation = model.plm.activation\n",
    "                except:\n",
    "                    activation = torch.nn.Tanh()\n",
    "                pooler_output = activation(dense(dropout(hidden_state[:, 0, :])))\n",
    "            hidden_states.extend(pooler_output.detach().cpu().tolist())\n",
    "        model.train()\n",
    "        return hidden_states, labels, poison_labels\n",
    "\n",
    "\n",
    "    def visualization(self, hidden_states: List, labels: List, poison_labels: List, fig_basepath: Optional[str]=\"./visualization\", fig_title: Optional[str]=\"vis\"):\n",
    "        \"\"\"\n",
    "        Visualize the latent representation of the victim model on the poisoned dataset and save to 'fig_basepath'.\n",
    "\n",
    "        Args:\n",
    "            hidden_states (:obj:`List`): the hidden state of the training data in all epochs.\n",
    "            labels (:obj:`List`): ground-truth label of the training data.\n",
    "            poison_labels (:obj:`List`): poison label of the poisoned training data.\n",
    "            fig_basepath (:obj:`str`, optional): dir path to save the model. Default to \"./visualization\".\n",
    "            fig_title (:obj:`str`, optional): title of the visualization result and the png file name. Default to \"vis\".\n",
    "        \"\"\"\n",
    "        logger.info('***** Visulizing *****')\n",
    "\n",
    "        dataset_len = int(len(poison_labels) / (self.epochs+1))\n",
    "\n",
    "        hidden_states= np.array(hidden_states)\n",
    "        labels = np.array(labels)\n",
    "        poison_labels = np.array(poison_labels, dtype=np.int64)\n",
    "\n",
    "        num_classes = len(set(labels))\n",
    "        \n",
    "        for epoch in tqdm(range(self.epochs+1)):\n",
    "            fig_title = f'Epoch {epoch}'\n",
    "\n",
    "            hidden_state = hidden_states[epoch*dataset_len : (epoch+1)*dataset_len]\n",
    "            label = labels[epoch*dataset_len : (epoch+1)*dataset_len]\n",
    "            poison_label = poison_labels[epoch*dataset_len : (epoch+1)*dataset_len]\n",
    "            poison_idx = np.where(poison_label==np.ones_like(poison_label))[0]\n",
    "\n",
    "            embedding_umap = self.dimension_reduction(hidden_state)\n",
    "            embedding = pd.DataFrame(embedding_umap)\n",
    "\n",
    "            for c in range(num_classes):\n",
    "                idx = np.where(label==int(c)*np.ones_like(label))[0]\n",
    "                idx = list(set(idx) ^ set(poison_idx))\n",
    "                plt.scatter(embedding.iloc[idx,0], embedding.iloc[idx,1], c=self.COLOR[c], s=1, label=c)\n",
    "\n",
    "            plt.scatter(embedding.iloc[poison_idx,0], embedding.iloc[poison_idx,1], s=1, c='gray', label='poison')\n",
    "\n",
    "            plt.tick_params(labelsize='large', length=2)\n",
    "            plt.legend(fontsize=14, markerscale=5, loc='lower right')\n",
    "            os.makedirs(fig_basepath, exist_ok=True)\n",
    "            plt.savefig(os.path.join(fig_basepath, f'{fig_title}.png'))\n",
    "            plt.savefig(os.path.join(fig_basepath, f'{fig_title}.pdf'))\n",
    "            fig_path = os.path.join(fig_basepath, f'{fig_title}.png')\n",
    "            logger.info(f'Saving png to {fig_path}')\n",
    "            plt.close()\n",
    "        return embedding_umap\n",
    "\n",
    "\n",
    "    def dimension_reduction(self, hidden_states: List, \n",
    "                            pca_components: Optional[int] = 20,\n",
    "                            n_neighbors: Optional[int] = 100,\n",
    "                            min_dist: Optional[float] = 0.5,\n",
    "                            umap_components: Optional[int] = 2):\n",
    "\n",
    "        pca = PCA(n_components=pca_components, \n",
    "                    random_state=42,\n",
    "                    )\n",
    "\n",
    "        umap = UMAP( n_neighbors=n_neighbors, \n",
    "                        min_dist=min_dist,\n",
    "                        n_components=umap_components,\n",
    "                        random_state=42,\n",
    "                        transform_seed=42,\n",
    "                        )\n",
    "\n",
    "        embedding_pca = pca.fit_transform(hidden_states)\n",
    "        embedding_umap = umap.fit(embedding_pca).embedding_\n",
    "        return embedding_umap\n",
    "\n",
    "\n",
    "    def clustering_metric(self, hidden_states: List, poison_labels: List, save_path: str):\n",
    "        \"\"\"\n",
    "        Compute the 'davies bouldin scores' for hidden states to track whether the poison samples can cluster together.\n",
    "\n",
    "        Args:\n",
    "            hidden_state (:obj:`List`): the hidden state of the training data in all epochs.\n",
    "            poison_labels (:obj:`List`): poison label of the poisoned training data.\n",
    "            save_path (:obj: `str`): path to save results. \n",
    "        \"\"\"\n",
    "        # dimension reduction\n",
    "        dataset_len = int(len(poison_labels) / (self.epochs+1))\n",
    "\n",
    "        hidden_states = np.array(hidden_states)\n",
    "\n",
    "        davies_bouldin_scores = []\n",
    "\n",
    "        for epoch in range(self.epochs+1):\n",
    "            hidden_state = hidden_states[epoch*dataset_len : (epoch+1)*dataset_len]\n",
    "            poison_label = poison_labels[epoch*dataset_len : (epoch+1)*dataset_len]\n",
    "            davies_bouldin_scores.append(davies_bouldin_score(hidden_state, poison_label))\n",
    "\n",
    "        np.save(os.path.join(save_path, 'davies_bouldin_scores.npy'), np.array(davies_bouldin_scores))\n",
    "\n",
    "        result = pd.DataFrame(columns=['davies_bouldin_score'])\n",
    "        for epoch, db_score in enumerate(davies_bouldin_scores):\n",
    "            result.loc[epoch, :] = [db_score]\n",
    "            result.to_csv(os.path.join(save_path, f'davies_bouldin_score.csv'))\n",
    "\n",
    "        return davies_bouldin_scores\n",
    "\n",
    "\n",
    "    def comp_loss(self, model, dataloader: torch.utils.data.DataLoader):\n",
    "        poison_loss_list, normal_loss_list = [], []\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            batch_inputs, batch_labels = self.model.process(batch)\n",
    "            output = self.model(batch_inputs)\n",
    "            logits = output.logits\n",
    "            loss = self.loss_function(logits, batch_labels)\n",
    "            \n",
    "            poison_labels = batch[\"poison_label\"]\n",
    "            for l, poison_label in zip(loss, poison_labels):\n",
    "                if poison_label == 1:\n",
    "                    poison_loss_list.append(l.item())\n",
    "                else:\n",
    "                    normal_loss_list.append(l.item())\n",
    "\n",
    "        avg_poison_loss = sum(poison_loss_list) / len(poison_loss_list) if self.visualize else 0\n",
    "        avg_normal_loss = sum(normal_loss_list) / len(normal_loss_list) if self.visualize else 0\n",
    "        \n",
    "        return avg_poison_loss, avg_normal_loss\n",
    "\n",
    "\n",
    "    def plot_curve(self, davies_bouldin_scores, normal_loss, poison_loss, fig_basepath: Optional[str]=\"./learning_curve\", fig_title: Optional[str]=\"fig\"):\n",
    "        \n",
    "\n",
    "        # bar of db score\n",
    "        fig, ax1 = plt.subplots()\n",
    "        \n",
    "        ax1.bar(range(self.epochs+1), davies_bouldin_scores, width=0.5, color='royalblue', label='davies bouldin score')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Davies Bouldin Score', size=14)\n",
    "\n",
    "\n",
    "        # curve of loss\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(range(self.epochs+1), normal_loss, linewidth=1.5, color='green',\n",
    "                    label=f'Normal Loss')\n",
    "        ax2.plot(range(self.epochs+1), poison_loss, linewidth=1.5, color='orange',\n",
    "                    label=f'Poison Loss')\n",
    "        ax2.set_ylabel('Loss', size=14)\n",
    "\n",
    "        \n",
    "        plt.title('Clustering Performance', size=14)\n",
    "        os.makedirs(fig_basepath, exist_ok=True)\n",
    "        plt.savefig(os.path.join(fig_basepath, f'{fig_title}.png'))\n",
    "        plt.savefig(os.path.join(fig_basepath, f'{fig_title}.pdf'))\n",
    "        fig_path = os.path.join(fig_basepath, f'{fig_title}.png')\n",
    "        logger.info(f'Saving png to {fig_path}')\n",
    "        plt.close()\n",
    "    \n",
    "\n",
    "    def save_vis(self):\n",
    "        hidden_path = os.path.join('./hidden_states', \n",
    "                        self.poison_setting, self.poison_method, str(self.poison_rate))\n",
    "        os.makedirs(hidden_path, exist_ok=True)\n",
    "        np.save(os.path.join(hidden_path, 'all_hidden_states.npy'), np.array(self.hidden_states))\n",
    "        np.save(os.path.join(hidden_path, 'labels.npy'), np.array(self.labels))\n",
    "        np.save(os.path.join(hidden_path, 'poison_labels.npy'), np.array(self.poison_labels))\n",
    "\n",
    "        embedding = self.visualization(self.hidden_states, self.labels, self.poison_labels, \n",
    "                        fig_basepath=os.path.join('./visualization', self.poison_setting, self.poison_method, str(self.poison_rate)))\n",
    "        np.save(os.path.join(hidden_path, 'embedding.npy'), embedding)\n",
    "\n",
    "        curve_path = os.path.join('./learning_curve', self.poison_setting, self.poison_method, str(self.poison_rate))\n",
    "        os.makedirs(curve_path, exist_ok=True)\n",
    "        davies_bouldin_scores = self.clustering_metric(self.hidden_states, self.poison_labels, curve_path)\n",
    "\n",
    "        np.save(os.path.join(curve_path, 'poison_loss.npy'), np.array(self.poison_loss_all))\n",
    "        np.save(os.path.join(curve_path, 'normal_loss.npy'), np.array(self.normal_loss_all))\n",
    "\n",
    "        self.plot_curve(davies_bouldin_scores, self.poison_loss_all, self.normal_loss_all, \n",
    "                        fig_basepath=curve_path)\n",
    "\n",
    "\n",
    "    def model_checkpoint(self, ckpt: str):\n",
    "        return os.path.join(self.save_path, f'{ckpt}.ckpt')\n",
    "\n",
    "\n",
    "class Poisoner(object):\n",
    "    r\"\"\"\n",
    "    Basic poisoner\n",
    "\n",
    "    Args:\n",
    "        name (:obj:`str`, optional): name of the poisoner. Default to \"Base\".\n",
    "        target_label (:obj:`int`, optional): the target label. Default to 0.\n",
    "        poison_rate (:obj:`float`, optional): the poison rate. Default to 0.1.\n",
    "        label_consistency (:obj:`bool`, optional): whether only poison the target samples. Default to `False`.\n",
    "        label_dirty (:obj:`bool`, optional): whether only poison the non-target samples. Default to `False`.\n",
    "        load (:obj:`bool`, optional): whether to load the poisoned data. Default to `False`.\n",
    "        poison_data_basepath (:obj:`str`, optional): the path to the fully poisoned data. Default to `None`.\n",
    "        poisoned_data_path (:obj:`str`, optional): the path to save the partially poisoned data. Default to `None`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        name: Optional[str]=\"Base\", \n",
    "        target_label: Optional[int] = 0,\n",
    "        poison_rate: Optional[float] = 0.1,\n",
    "        label_consistency: Optional[bool] = False,\n",
    "        label_dirty: Optional[bool] = False,\n",
    "        load: Optional[bool] = False,\n",
    "        poison_data_basepath: Optional[str] = None,\n",
    "        poisoned_data_path: Optional[str] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        print(kwargs)\n",
    "        self.name = name\n",
    "\n",
    "        self.target_label = target_label\n",
    "        self.poison_rate = poison_rate        \n",
    "        self.label_consistency = label_consistency\n",
    "        self.label_dirty = label_dirty\n",
    "        self.load = load\n",
    "        self.poison_data_basepath = poison_data_basepath\n",
    "        self.poisoned_data_path = poisoned_data_path\n",
    "\n",
    "        if label_consistency:\n",
    "            self.poison_setting = 'clean'\n",
    "        elif label_dirty:\n",
    "            self.poison_setting = 'dirty'\n",
    "        else:\n",
    "            self.poison_setting = 'mix'\n",
    "\n",
    "\n",
    "    def __call__(self, data: Dict, mode: str):\n",
    "        \"\"\"\n",
    "        Poison the data.\n",
    "        In the \"train\" mode, the poisoner will poison the training data based on poison ratio and label consistency. Return the mixed training data.\n",
    "        In the \"eval\" mode, the poisoner will poison the evaluation data. Return the clean and poisoned evaluation data.\n",
    "        In the \"detect\" mode, the poisoner will poison the evaluation data. Return the mixed evaluation data.\n",
    "\n",
    "        Args:\n",
    "            data (:obj:`Dict`): the data to be poisoned.\n",
    "            mode (:obj:`str`): the mode of poisoning. Can be \"train\", \"eval\" or \"detect\". \n",
    "\n",
    "        Returns:\n",
    "            :obj:`Dict`: the poisoned data.\n",
    "        \"\"\"\n",
    "\n",
    "        poisoned_data = defaultdict(list)\n",
    "\n",
    "        if mode == \"train\":\n",
    "            if self.load and os.path.exists(os.path.join(self.poisoned_data_path, \"train-poison.csv\")):\n",
    "                poisoned_data[\"train\"] = self.load_poison_data(self.poisoned_data_path, \"train-poison\") \n",
    "            else:\n",
    "                if self.load and os.path.exists(os.path.join(self.poison_data_basepath, \"train-poison.csv\")):\n",
    "                    poison_train_data = self.load_poison_data(self.poison_data_basepath, \"train-poison\")\n",
    "                else:\n",
    "                    poison_train_data = self.poison(data[\"train\"])\n",
    "                    self.save_data(data[\"train\"], self.poison_data_basepath, \"train-clean\")\n",
    "                    self.save_data(poison_train_data, self.poison_data_basepath, \"train-poison\")\n",
    "                poisoned_data[\"train\"] = self.poison_part(data[\"train\"], poison_train_data)\n",
    "                self.save_data(poisoned_data[\"train\"], self.poisoned_data_path, \"train-poison\")\n",
    "\n",
    "\n",
    "            poisoned_data[\"dev-clean\"] = data[\"dev\"]\n",
    "            if self.load and os.path.exists(os.path.join(self.poison_data_basepath, \"dev-poison.csv\")):\n",
    "                poisoned_data[\"dev-poison\"] = self.load_poison_data(self.poison_data_basepath, \"dev-poison\") \n",
    "            else:\n",
    "                poisoned_data[\"dev-poison\"] = self.poison(self.get_non_target(data[\"dev\"]))\n",
    "                self.save_data(data[\"dev\"], self.poison_data_basepath, \"dev-clean\")\n",
    "                self.save_data(poisoned_data[\"dev-poison\"], self.poison_data_basepath, \"dev-poison\")\n",
    "       \n",
    "\n",
    "        elif mode == \"eval\":\n",
    "            poisoned_data[\"test-clean\"] = data[\"test\"]\n",
    "            if self.load and os.path.exists(os.path.join(self.poison_data_basepath, \"test-poison.csv\")):\n",
    "                poisoned_data[\"test-poison\"] = self.load_poison_data(self.poison_data_basepath, \"test-poison\")\n",
    "            else:\n",
    "                poisoned_data[\"test-poison\"] = self.poison(self.get_non_target(data[\"test\"]))\n",
    "                self.save_data(data[\"test\"], self.poison_data_basepath, \"test-clean\")\n",
    "                self.save_data(poisoned_data[\"test-poison\"], self.poison_data_basepath, \"test-poison\")\n",
    "                \n",
    "                \n",
    "        elif mode == \"detect\":\n",
    "            if self.load and os.path.exists(os.path.join(self.poison_data_basepath, \"test-detect.csv\")):\n",
    "                poisoned_data[\"test-detect\"] = self.load_poison_data(self.poison_data_basepath, \"test-detect\")\n",
    "            else:\n",
    "                if self.load and os.path.exists(os.path.join(self.poison_data_basepath, \"test-poison.csv\")):\n",
    "                    poison_test_data = self.load_poison_data(self.poison_data_basepath, \"test-poison\")\n",
    "                else:\n",
    "                    poison_test_data = self.poison(self.get_non_target(data[\"test\"]))\n",
    "                    self.save_data(data[\"test\"], self.poison_data_basepath, \"test-clean\")\n",
    "                    self.save_data(poison_test_data, self.poison_data_basepath, \"test-poison\")\n",
    "                poisoned_data[\"test-detect\"] = data[\"test\"] + poison_test_data\n",
    "                #poisoned_data[\"test-detect\"] = self.poison_part(data[\"test\"], poison_test_data)\n",
    "                self.save_data(poisoned_data[\"test-detect\"], self.poison_data_basepath, \"test-detect\")\n",
    "            \n",
    "        return poisoned_data\n",
    "    \n",
    "    \n",
    "    def get_non_target(self, data):\n",
    "        \"\"\"\n",
    "        Get data of non-target label.\n",
    "\n",
    "        \"\"\"\n",
    "        return [d for d in data if d[1] != self.target_label]\n",
    "\n",
    "\n",
    "    def poison_part(self, clean_data: List, poison_data: List):\n",
    "        \"\"\"\n",
    "        Poison part of the data.\n",
    "\n",
    "        Args:\n",
    "            data (:obj:`List`): the data to be poisoned.\n",
    "        \n",
    "        Returns:\n",
    "            :obj:`List`: the poisoned data.\n",
    "        \"\"\"\n",
    "        poison_num = int(self.poison_rate * len(clean_data))\n",
    "        \n",
    "        if self.label_consistency:\n",
    "            target_data_pos = [i for i, d in enumerate(clean_data) if d[1]==self.target_label] \n",
    "        elif self.label_dirty:\n",
    "            target_data_pos = [i for i, d in enumerate(clean_data) if d[1]!=self.target_label]\n",
    "        else:\n",
    "            target_data_pos = [i for i, d in enumerate(clean_data)]\n",
    "\n",
    "        if len(target_data_pos) < poison_num:\n",
    "            logger.warning(\"Not enough data for clean label attack.\")\n",
    "            poison_num = len(target_data_pos)\n",
    "        random.shuffle(target_data_pos)\n",
    "\n",
    "        poisoned_pos = target_data_pos[:poison_num]\n",
    "        clean = [d for i, d in enumerate(clean_data) if i not in poisoned_pos]\n",
    "        poisoned = [d for i, d in enumerate(poison_data) if i in poisoned_pos]\n",
    "\n",
    "        return clean + poisoned\n",
    "\n",
    "\n",
    "    def poison(self, data: List):\n",
    "        \"\"\"\n",
    "        Poison all the data.\n",
    "\n",
    "        Args:\n",
    "            data (:obj:`List`): the data to be poisoned.\n",
    "        \n",
    "        Returns:\n",
    "            :obj:`List`: the poisoned data.\n",
    "        \"\"\"\n",
    "        return data\n",
    "\n",
    "    def load_poison_data(self, path, split):\n",
    "        if path is not None:\n",
    "            data = pd.read_csv(os.path.join(path, f'{split}.csv')).values\n",
    "            poisoned_data = [(d[1], d[2], d[3]) for d in data]\n",
    "            return poisoned_data\n",
    "\n",
    "    def save_data(self, dataset, path, split):\n",
    "        if path is not None:\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            dataset = pd.DataFrame(dataset)\n",
    "            dataset.to_csv(os.path.join(path, f'{split}.csv'))\n",
    "\n",
    "\n",
    "class Attacker(object):\n",
    "    \"\"\"\n",
    "    The base class of all attackers. Each attacker has a poisoner and a trainer.\n",
    "\n",
    "    Args:\n",
    "        poisoner (:obj:`dict`, optional): the config of poisoner.\n",
    "        train (:obj:`dict`, optional): the config of poison trainer.\n",
    "        metrics (`List[str]`, optional): the metrics to evaluate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            poisoner: Optional[dict] = {\"name\": \"base\"},\n",
    "            train: Optional[dict] = {\"name\": \"base\"},\n",
    "            metrics: Optional[List[str]] = [\"accuracy\"],\n",
    "            sample_metrics: Optional[List[str]] = [],\n",
    "            **kwargs\n",
    "    ):\n",
    "        self.metrics = metrics\n",
    "        self.sample_metrics = sample_metrics\n",
    "        self.poisoner_config = poisoner\n",
    "        self.trainer_config = train\n",
    "        self.poisoner = load_poisoner(poisoner)\n",
    "        self.poison_trainer = load_trainer(dict(poisoner, **train, **{\"poison_method\":poisoner[\"name\"]}))\n",
    "\n",
    "    def attack(self, victim, data: List, config: Optional[dict] = None, defender = None):\n",
    "        \"\"\"\n",
    "        Attack the victim model with the attacker.\n",
    "\n",
    "        Args:\n",
    "            victim (:obj:`Victim`): the victim to attack.\n",
    "            data (:obj:`List`): the dataset to attack.\n",
    "            defender (:obj:`Defender`, optional): the defender.\n",
    "\n",
    "        Returns:\n",
    "            :obj:`Victim`: the attacked model.\n",
    "\n",
    "        \"\"\"\n",
    "        poison_dataset = self.poison(victim, data, \"train\")\n",
    "\n",
    "        if defender is not None and defender.pre is True:\n",
    "            # pre tune defense\n",
    "            poison_dataset[\"train\"] = defender.correct(poison_data=poison_dataset['train'])\n",
    "\n",
    "        backdoored_model = self.train(victim, poison_dataset)\n",
    "        return backdoored_model\n",
    "\n",
    "    def poison(self, victim, dataset: List, mode: str):\n",
    "        \"\"\"\n",
    "        Default poisoning function.\n",
    "\n",
    "        Args:\n",
    "            victim (:obj:`Victim`): the victim to attack.\n",
    "            dataset (:obj:`List`): the dataset to attack.\n",
    "            mode (:obj:`str`): the mode of poisoning. \n",
    "        \n",
    "        Returns:\n",
    "            :obj:`List`: the poisoned dataset.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.poisoner(dataset, mode)\n",
    "\n",
    "    def train(self, victim, dataset: List):\n",
    "        \"\"\"\n",
    "        Use ``poison_trainer`` to attack the victim model.\n",
    "        default training: normal training\n",
    "\n",
    "        Args:\n",
    "            victim (:obj:`Victim`): the victim to attack.\n",
    "            dataset (:obj:`List`): the dataset to attack.\n",
    "    \n",
    "        Returns:\n",
    "            :obj:`Victim`: the attacked model.\n",
    "        \"\"\"\n",
    "        return self.poison_trainer.train(victim, dataset, self.metrics)\n",
    "\n",
    "    def eval(self, victim, dataset: List, defender = None):\n",
    "        \"\"\"\n",
    "        Default evaluation function (ASR and CACC) for the attacker.\n",
    "            \n",
    "        Args:\n",
    "            victim (:obj:`Victim`): the victim to attack.\n",
    "            dataset (:obj:`List`): the dataset to attack.\n",
    "            defender (:obj:`Defender`, optional): the defender.\n",
    "\n",
    "        Returns:\n",
    "            :obj:`dict`: the evaluation results.\n",
    "        \"\"\"\n",
    "        poison_dataset = self.poison(victim, dataset, \"eval\")\n",
    "        if defender is not None and defender.pre is False:\n",
    "            \n",
    "            if defender.correction:\n",
    "                poison_dataset[\"test-clean\"] = defender.correct(model=victim, clean_data=dataset, poison_data=poison_dataset[\"test-clean\"])\n",
    "                poison_dataset[\"test-poison\"] = defender.correct(model=victim, clean_data=dataset, poison_data=poison_dataset[\"test-poison\"])\n",
    "            else:\n",
    "                # post tune defense\n",
    "                detect_poison_dataset = self.poison(victim, dataset, \"detect\")\n",
    "                detection_score, preds = defender.eval_detect(model=victim, clean_data=dataset, poison_data=detect_poison_dataset)\n",
    "                \n",
    "                clean_length = len(poison_dataset[\"test-clean\"])\n",
    "                num_classes = len(set([data[1] for data in poison_dataset[\"test-clean\"]]))\n",
    "                preds_clean, preds_poison = preds[:clean_length], preds[clean_length:]\n",
    "                poison_dataset[\"test-clean\"] = [(data[0], num_classes, 0) if pred == 1 else (data[0], data[1], 0) for pred, data in zip(preds_clean, poison_dataset[\"test-clean\"])]\n",
    "                poison_dataset[\"test-poison\"] = [(data[0], num_classes, 0) if pred == 1 else (data[0], data[1], 0) for pred, data in zip(preds_poison, poison_dataset[\"test-poison\"])]\n",
    "\n",
    "\n",
    "        poison_dataloader = wrap_dataset(poison_dataset, self.trainer_config[\"batch_size\"])\n",
    "        \n",
    "        results = evaluate_classification(victim, poison_dataloader, self.metrics)\n",
    "\n",
    "        sample_metrics = self.eval_poison_sample(victim, dataset, self.sample_metrics)\n",
    "\n",
    "        return dict(results[0], **sample_metrics)\n",
    "\n",
    "\n",
    "    def eval_poison_sample(self, victim, dataset: List, eval_metrics=[]):\n",
    "        \"\"\"\n",
    "        Evaluation function for the poison samples (PPL, Grammar Error, and USE).\n",
    "\n",
    "        Args:\n",
    "            victim (:obj:`Victim`): the victim to attack.\n",
    "            dataset (:obj:`List`): the dataset to attack.\n",
    "            eval_metrics (:obj:`List`): the metrics for samples. \n",
    "        \n",
    "        Returns:\n",
    "            :obj:`List`: the poisoned dataset.\n",
    "\n",
    "        \"\"\"\n",
    "        evaluator = Evaluator()\n",
    "        sample_metrics = {\"ppl\": np.nan, \"grammar\": np.nan, \"use\": np.nan}\n",
    "        \n",
    "        poison_dataset = self.poison(victim, dataset, \"eval\")\n",
    "        clean_test = self.poisoner.get_non_target(poison_dataset[\"test-clean\"])\n",
    "        poison_test = poison_dataset[\"test-poison\"]\n",
    "\n",
    "        for metric in eval_metrics:\n",
    "            if metric not in ['ppl', 'grammar', 'use']:\n",
    "                logger.info(\"  Invalid Eval Metric, return  \")\n",
    "            measure = 0\n",
    "            if metric == 'ppl':\n",
    "                measure = evaluator.evaluate_ppl([item[0] for item in clean_test], [item[0] for item in poison_test])\n",
    "            if metric == 'grammar':\n",
    "                measure = evaluator.evaluate_grammar([item[0] for item in clean_test], [item[0] for item in poison_test])\n",
    "            if metric == 'use':\n",
    "                measure = evaluator.evaluate_use([item[0] for item in clean_test], [item[0] for item in poison_test])\n",
    "            logger.info(\"  Eval Metric: {} =  {}\".format(metric, measure))\n",
    "            sample_metrics[metric] = measure\n",
    "        \n",
    "        return sample_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5ede5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a695f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b026c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae9ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d4f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb4fce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74118b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
